import time
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import matplotlib.pyplot as plt

# --- 1. è¨­å®šèˆ‡è¨­å‚™ ---
if torch.backends.mps.is_available():
    device = torch.device("mps")
else:
    device = torch.device("cpu")
print(f" usando {device} é€²è¡Œé‹ç®—")

# å®šç¾© Fashion-MNIST çš„ 10 å€‹é¡åˆ¥åç¨±
classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 
           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# --- 2. å®šç¾©å¤§è…¦çµæ§‹ (CNN å·ç©ç¥ç¶“ç¶²è·¯) ---
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.fc1 = nn.Linear(9216, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        return F.log_softmax(self.fc2(x), dim=1)

# --- 3. æº–å‚™æ•¸æ“š (æ”¹ç‚º Fashion-MNIST) ---
# Fashion-MNIST çš„å¹³å‡å€¼èˆ‡æ¨™æº–å·®ç•¥æœ‰ä¸åŒï¼Œä½†ä½¿ç”¨ (0.5, 0.5) ä¹Ÿå¾ˆé€šç”¨
transform = transforms.Compose([
    transforms.ToTensor(), 
    transforms.Normalize((0.5,), (0.5,))
])

# è¼‰å…¥è¨“ç·´é›†
train_loader = torch.utils.data.DataLoader(
    datasets.FashionMNIST('./data', train=True, download=True, transform=transform), 
    batch_size=64, shuffle=True)

model = Net().to(device)
MODEL_PATH = "fashion_mnist_model.pth"

# --- 4. æ ¸å¿ƒé‚è¼¯ï¼šè®€å–æˆ–è¨“ç·´ ---
choice = "n" 
if os.path.exists(MODEL_PATH):
    # é€™è£¡åŠ å…¥ä¸€å€‹ try-except é˜²æ­¢è¼¸å…¥è¢«è·³é
    try:
        choice = input(f"åµæ¸¬åˆ° '{MODEL_PATH}'ï¼Œæ˜¯å¦è¼‰å…¥ï¼Ÿ (y/n): ").lower()
    except EOFError:
        choice = "n"

if choice == 'y':
    print("â³ æ­£åœ¨è¼‰å…¥æ™‚å°šå¤§è…¦...")
    state_dict = torch.load(MODEL_PATH, map_location=device, weights_only=True)
    model.load_state_dict(state_dict)
    print("âœ… è¼‰å…¥æˆåŠŸï¼")
else:
    print("\nğŸš€ é–‹å§‹è¨“ç·´æ™‚å°šåˆ†æå¸« (é è¨ˆ 5 è¼ªï¼Œå› ç‚ºè¡£æœæ¯”æ•¸å­—é›£åˆ†è¾¨)...")
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    for epoch in range(1, 6): # å¢åŠ åˆ° 5 è¼ªæ•ˆæœæ›´å¥½
        model.train()
        start_time = time.time()
        running_loss = 0.0
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = F.nll_loss(output, target)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        
        duration = time.time() - start_time
        print(f"ç¬¬ {epoch} è¼ªå®Œæˆï¼Œå¹³å‡ Loss: {running_loss/len(train_loader):.4f}ï¼Œè€—æ™‚: {duration:.2f} ç§’")
    
    torch.save(model.state_dict(), MODEL_PATH)
    print(f"ğŸ’¾ å¤§è…¦å·²å­˜æª”è‡³ {MODEL_PATH}")

# --- 5. éš¨å ‚æ¸¬é©— ---
print("\n--- æ™‚å°šå¤§æŒ‘æˆ° ---")
model.eval()
test_data, test_target = next(iter(train_loader))
img = test_data[0].unsqueeze(0).to(device)

with torch.no_grad():
    output = model(img)
    prediction_idx = output.argmax(dim=1, keepdim=True).item()
    prediction_name = classes[prediction_idx]
    actual_name = classes[test_target[0].item()]

print(f"AI åˆ¤æ–·é€™ä»¶è¡£æœæ˜¯: {prediction_name}")
print(f"å¯¦éš›ç­”æ¡ˆæ˜¯: {actual_name}")

# --- 6. è¦–è¦ºåŒ–é¡¯ç¤º ---
plt.imshow(test_data[0].squeeze().cpu().numpy(), cmap='gray')
plt.title(f"AI Predict: {prediction_name}\nActual: {actual_name}")
plt.axis('off')
plt.show()